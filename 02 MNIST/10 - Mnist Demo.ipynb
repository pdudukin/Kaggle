{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZ4yAtkoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bfc90659e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=3\n",
    "img=train.iloc[i,1:].as_matrix()\n",
    "img=img.reshape((28,28))\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.title(train.iloc[i,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.iloc[:,1:].as_matrix()\n",
    "y = train.iloc[:,0]\n",
    "y_ = MultiLabelBinarizer().fit_transform(y.values.reshape(-1,1))\n",
    "y_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(preds):\n",
    "    return np.argmax(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle: 0.90729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=0,n_jobs=-1)\n",
    "ovrc = OneVsRestClassifier(lr,n_jobs=-1)\n",
    "%time ovrc.fit(X, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ovrc.score(X,y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = ovrc.predict_proba(test)\n",
    "pd.DataFrame({\n",
    "    'ImageId':range(1,28001),\n",
    "    'Label':pd.DataFrame(pred).apply(softmax,axis=1)\n",
    "}).to_csv('./submissions/logreg_ovrc_v1.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    v0 = ovrc.estimators_[i]\n",
    "    img=v0.coef_[0].reshape((28,28))\n",
    "    print(i,np.min(img),np.max(img))\n",
    "    plt.imshow(img,cmap='bwr',vmin=-.01,vmax=.01)\n",
    "    #plt.title(i)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle: 0.94243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = rfc.feature_importances_\n",
    "img=img.reshape((28,28))\n",
    "print(np.min(img),np.max(img))\n",
    "plt.imshow(img,cmap='Greys_r',vmin=0,vmax=.018)\n",
    "plt.title(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = rfc.predict(test)\n",
    "pd.DataFrame({\n",
    "    'ImageId':range(1,28001),\n",
    "    'Label':pred\n",
    "}).to_csv('./submissions/rfc_a_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest One vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "ova_rfc = OneVsRestClassifier(rfc,n_jobs=-1)\n",
    "%time ova_rfc.fit(X, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ova_rfc.score(X,y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    v0 = ova_rfc.estimators_[i]\n",
    "    img=v0.feature_importances_.reshape((28,28))\n",
    "    print(np.min(img),np.max(img))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img,cmap='bwr',vmin=-.01,vmax=.01)\n",
    "    #plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(preds):\n",
    "    return np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = ova_rfc.predict_proba(test)\n",
    "pd.DataFrame({\n",
    "    'ImageId':range(1,28001),\n",
    "    'Label':pd.DataFrame(pred).apply(softmax,axis=1)\n",
    "}).to_csv('./submissions/rfc_ova_v4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706.0\n",
      "Trainable params: 669,706.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "42000/42000 [==============================] - 11s - loss: 0.2830 - acc: 0.9121    - ETA: 3s - loss: 0.3395\n",
      "Epoch 2/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.1154 - acc: 0.9642    \n",
      "Epoch 3/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0803 - acc: 0.9748    \n",
      "Epoch 4/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0638 - acc: 0.9794    - ETA: 0s - loss: 0.0633 - acc: 0\n",
      "Epoch 5/40\n",
      "42000/42000 [==============================] - 11s - loss: 0.0508 - acc: 0.9842    \n",
      "Epoch 6/40\n",
      "42000/42000 [==============================] - 11s - loss: 0.0427 - acc: 0.9861    \n",
      "Epoch 7/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0370 - acc: 0.9887    \n",
      "Epoch 8/40\n",
      "42000/42000 [==============================] - 11s - loss: 0.0322 - acc: 0.9901    \n",
      "Epoch 9/40\n",
      "42000/42000 [==============================] - 11s - loss: 0.0284 - acc: 0.9911    \n",
      "Epoch 10/40\n",
      "42000/42000 [==============================] - 11s - loss: 0.0278 - acc: 0.9912    \n",
      "Epoch 11/40\n",
      "42000/42000 [==============================] - 11s - loss: 0.0243 - acc: 0.9926    \n",
      "Epoch 12/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0225 - acc: 0.9932    \n",
      "Epoch 13/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0230 - acc: 0.9937    \n",
      "Epoch 14/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0184 - acc: 0.9945    \n",
      "Epoch 15/40\n",
      "42000/42000 [==============================] - 9s - loss: 0.0176 - acc: 0.9949     \n",
      "Epoch 16/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0162 - acc: 0.9953    \n",
      "Epoch 17/40\n",
      "42000/42000 [==============================] - 9s - loss: 0.0154 - acc: 0.9957     \n",
      "Epoch 18/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0160 - acc: 0.9953    \n",
      "Epoch 19/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0145 - acc: 0.9961    \n",
      "Epoch 20/40\n",
      "42000/42000 [==============================] - 9s - loss: 0.0136 - acc: 0.9960     \n",
      "Epoch 21/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0130 - acc: 0.9963    \n",
      "Epoch 22/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0132 - acc: 0.9965    \n",
      "Epoch 23/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0135 - acc: 0.9965    \n",
      "Epoch 24/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0127 - acc: 0.9964    \n",
      "Epoch 25/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0128 - acc: 0.9965    \n",
      "Epoch 26/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0140 - acc: 0.9961    \n",
      "Epoch 27/40\n",
      "42000/42000 [==============================] - 9s - loss: 0.0089 - acc: 0.9975     \n",
      "Epoch 28/40\n",
      "42000/42000 [==============================] - 9s - loss: 0.0121 - acc: 0.9969     \n",
      "Epoch 29/40\n",
      "42000/42000 [==============================] - 9s - loss: 0.0128 - acc: 0.9971     \n",
      "Epoch 30/40\n",
      "42000/42000 [==============================] - 9s - loss: 0.0116 - acc: 0.9971     - ETA: 1s -\n",
      "Epoch 31/40\n",
      "42000/42000 [==============================] - 9s - loss: 0.0116 - acc: 0.9971     \n",
      "Epoch 32/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0116 - acc: 0.9972    \n",
      "Epoch 33/40\n",
      "42000/42000 [==============================] - 9s - loss: 0.0093 - acc: 0.9976     \n",
      "Epoch 34/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0105 - acc: 0.9975    \n",
      "Epoch 35/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0095 - acc: 0.9975    \n",
      "Epoch 36/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0116 - acc: 0.9973    \n",
      "Epoch 37/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0104 - acc: 0.9973    \n",
      "Epoch 38/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0099 - acc: 0.9975    \n",
      "Epoch 39/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0095 - acc: 0.9977    \n",
      "Epoch 40/40\n",
      "42000/42000 [==============================] - 10s - loss: 0.0093 - acc: 0.9979    \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X/255,y_,batch_size=batch_size,epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test.values/255)\n",
    "pd.DataFrame({\n",
    "    'ImageId':range(1,28001),\n",
    "    'Label':pd.DataFrame(pred).apply(softmax,axis=1)\n",
    "}).to_csv('keras_a_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6f644443e3af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names)\u001b[0m\n\u001b[0;32m     98\u001b[0m                \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                show_layer_names=True):\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     18\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 512)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(index=1).get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ae4fd167fc33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "\n",
    "\n",
    "def plot(model, to_file):\n",
    "\n",
    "    graph = pydot.Dot(graph_type='digraph')\n",
    "\n",
    "    previous_node = None\n",
    "    written_nodes = []\n",
    "    n = 1\n",
    "    for node in model.get_config()['layers']:\n",
    "        if (node['name'] + str(n)) in written_nodes:\n",
    "            n += 1\n",
    "        current_node = pydot.Node(node['name'] + str(n))\n",
    "        written_nodes.append(node['name'] + str(n))\n",
    "        graph.add_node(current_node)\n",
    "        if previous_node:\n",
    "            graph.add_edge(pydot.Edge(previous_node, current_node))\n",
    "        previous_node = current_node\n",
    "    graph.write_png(to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b1ebbb666e03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'keras.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "plot(model,'keras.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'get_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-da4f4fed1498>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md3viz\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0md3v\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0md3v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md3viz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test.html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'get_output'"
     ]
    }
   ],
   "source": [
    "import theano.d3viz as d3v\n",
    "d3v.d3viz(model.get_output(), 'test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784 (784, 512)\n",
      "512 (512,)\n",
      "512 (512, 512)\n",
      "512 (512,)\n",
      "512 (512, 10)\n",
      "10 (10,)\n"
     ]
    }
   ],
   "source": [
    "w = model.get_weights()\n",
    "for i in range(len(w)):\n",
    "    print(len(w[i]),w[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(w[2][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(w[0]*w[1]*w[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = model.get_layer(index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmax(x,i):\n",
    "    v = model.predict_proba(np.array([0.5]*784).reshape(1,-1),verbose=0)[0]\n",
    "    return 1 - (v[i]*2 - sum(v))\n",
    "def kmax0(x):\n",
    "    return kmax(x,0)\n",
    "def kmax1(x):\n",
    "    return kmax(x,1)\n",
    "def kmax2(x):\n",
    "    return kmax(x,2)\n",
    "def kmax3(x):\n",
    "    return kmax(x,3)\n",
    "def kmax4(x):\n",
    "    return kmax(x,4)\n",
    "def kmax5(x):\n",
    "    return kmax(x,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmax0(x):\n",
    "    return 1. - model.predict_proba(x.reshape(1,-1),verbose=0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmax0(test.loc[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict_proba(np.array([0.5]*784).reshape(1,-1),verbose=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = minimize(kmax0,options={'disp':True},tol=0.00001,method='COBYLA',x0=[0]*784)#np.zeros(784))\n",
    "img = r.x.reshape(28,28)\n",
    "print(np.min(img),np.max(img))\n",
    "plt.imshow(img,cmap='bwr')\n",
    "plt.title(0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = minimize(kmax1,np.zeros(784))\n",
    "img = r.x.reshape(28,28)\n",
    "print(np.min(img),np.max(img))\n",
    "plt.imshow(img,cmap='bwr')\n",
    "plt.title(1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = minimize(kmax2,np.zeros(784))\n",
    "img = r.x.reshape(28,28)\n",
    "print(np.min(img),np.max(img))\n",
    "plt.imshow(img,cmap='bwr')\n",
    "plt.title(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = minimize(kmax3,np.zeros(784))\n",
    "img = r.x.reshape(28,28)\n",
    "print(np.min(img),np.max(img))\n",
    "plt.imshow(img,cmap='bwr')\n",
    "plt.title(3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = minimize(kmax4,np.zeros(784))\n",
    "img = r.x.reshape(28,28)\n",
    "print(np.min(img),np.max(img))\n",
    "plt.imshow(img,cmap='bwr')\n",
    "plt.title(4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = minimize(kmax5,[0.5]*784)#np.zeros(784))\n",
    "img = r.x.reshape(28,28)\n",
    "print(np.min(img),np.max(img))\n",
    "plt.imshow(img,cmap='bwr')\n",
    "plt.title(5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(model.layers)+1):\n",
    "    l = model.get_layer(index=i)\n",
    "    if len(l.weights)>0:\n",
    "        print('==== Layer',i,'====')\n",
    "        w = l.get_weights()\n",
    "        print('first element',w[0].shape,':\\n',w[0])\n",
    "        print('second element',w[1].shape,':\\n',w[1])\n",
    "#model.get_layer(index=0).get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#r = np.dot(np.dot(a,b),c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = model.get_layer(index=1).get_weights()[0]\n",
    "a_ = model.get_layer(index=1).get_weights()[1]\n",
    "b = model.get_layer(index=3).get_weights()[0]\n",
    "b_ = model.get_layer(index=3).get_weights()[1]\n",
    "c = model.get_layer(index=5).get_weights()[0]\n",
    "c_ = model.get_layer(index=5).get_weights()[1]\n",
    "r = np.dot(np.dot(a-a_,b)-b_,c)-c_\n",
    "for i in range(10):\n",
    "    img = r[:,i].reshape(28,28)\n",
    "    print(np.min(img),np.max(img))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img,cmap='bwr')\n",
    "    #plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    s = train[train['label']==i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = train.groupby(by='label').mean()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    img = m.ix[i].values.reshape(28,28)\n",
    "    print(np.min(img),np.max(img))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img,cmap='bwr')\n",
    "    #plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 15\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(784, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(392, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(196, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(49, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X/255,y_,batch_size=batch_size,epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test.values/255)\n",
    "pd.DataFrame({\n",
    "    'ImageId':range(1,28001),\n",
    "    'Label':pd.DataFrame(pred).apply(softmax,axis=1)\n",
    "}).to_csv('./submissions/keras_a_v5.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.iloc[:,1:].as_matrix()\n",
    "y = train.iloc[:,0]\n",
    "y_ = MultiLabelBinarizer().fit_transform(y.values.reshape(-1,1))\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28,28\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(keras.layers.normalization.BatchNormalization(input_shape=input_shape))\n",
    "model.add(Conv2D(49, (5,5), activation='relu', kernel_initializer='he_normal'))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu',kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#hist = model.fit(x_train, y_train,\n",
    "#          batch_size=200,\n",
    "#          epochs=30,\n",
    "#          verbose=1,validation_split=0.3)\n",
    "#score = model.evaluate(x_train, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_test = test.as_matrix().reshape(test.shape[0], 1, img_rows, img_cols)\n",
    "else:\n",
    "    x_test = test.as_matrix().reshape(test.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "pd.DataFrame({\n",
    "    'ImageId':range(1,28001),\n",
    "    'Label':pd.DataFrame(pred).apply(softmax,axis=1)\n",
    "}).to_csv('./submissions/keras_conv_v8.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./mnist_model_cnn_v5.dat')\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='mnist_model.png',show_layer_names=True,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(filepath='./mnist_model_cnn_v5.dat',include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(model.predict(x_train)).apply(softmax,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = train.copy()\n",
    "a['pred'] = pred\n",
    "a = a[a['label'] != a['pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(a)):\n",
    "    plt.title('Prediction: '+str(a.iloc[i,-1])+', Label: '+str(a.iloc[i,0]))\n",
    "    img = a.iloc[i,1:-1].values.reshape(28,28)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img,cmap='bwr')\n",
    "    #plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
